{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('Julie', 1), ('loves', 2), ('me', 2), ('more', 1), ('than', 1), ('Linda', 1)])\n",
      "dict_items([('Jane', 1), ('likes', 1), ('me', 2), ('more', 1), ('than', 1), ('Julie', 1), ('loves', 1)])\n",
      "dict_items([('He', 1), ('likes', 1), ('basketball', 1), ('more', 1), ('than', 1), ('baseball', 1)])\n"
     ]
    }
   ],
   "source": [
    "mydoclist = ['Julie loves me more than Linda loves me',\n",
    "'Jane likes me more than Julie loves me',\n",
    "'He likes basketball more than baseball']\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "for doc in mydoclist:\n",
    "    tf = Counter()\n",
    "    for word in doc.split():\n",
    "        tf[word] += 1\n",
    "    print(tf.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary vector is [likes, basketball, Linda, loves, Jane, baseball, than, He, more, Julie, me]\n",
      "The doc is \"Julie loves me more than Linda loves me\"\n",
      "the tf vector for Document 1 is [0, 0, 1, 2, 0, 0, 1, 0, 1, 1, 2]\n",
      "The doc is \"Jane likes me more than Julie loves me\"\n",
      "the tf vector for Document 2 is [1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 2]\n",
      "The doc is \"He likes basketball more than baseball\"\n",
      "the tf vector for Document 3 is [1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0]\n",
      "All Combined here is our master document term matrix: \n",
      "[[0, 0, 1, 2, 0, 0, 1, 0, 1, 1, 2], [1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 2], [1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "def build_lexicon(corpus):\n",
    "    lexicon = set()\n",
    "    for doc in corpus:\n",
    "        lexicon.update([word for word in doc.split()])\n",
    "    return lexicon\n",
    "\n",
    "def tf(term, document):\n",
    "    return freq(term, document)\n",
    "\n",
    "def freq(term, document):\n",
    "    return document.split().count(term)\n",
    "\n",
    "vocabulary = build_lexicon(mydoclist)\n",
    "\n",
    "doc_term_matrix = []\n",
    "print('Our vocabulary vector is [' + ', '.join(list(vocabulary)) + ']')\n",
    "\n",
    "for doc in mydoclist:\n",
    "    print('The doc is \"' + doc + '\"')\n",
    "    tf_vector = [tf(word, doc) for word in vocabulary]\n",
    "    tf_vector_string = ', '.join(format(freq, 'd')for freq in tf_vector)\n",
    "    print('the tf vector for Document %d is [%s]'%((mydoclist.index(doc)+1), tf_vector_string))\n",
    "    doc_term_matrix.append(tf_vector)\n",
    "    \n",
    "print('All Combined here is our master document term matrix: ')\n",
    "print(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
